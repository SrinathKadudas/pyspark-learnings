{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa845c47",
   "metadata": {},
   "source": [
    "# Pyspark handling missing values\n",
    "- dropping columns\n",
    "- dropping rows\n",
    "- various parameters in dropping functionalites\n",
    "- handling missing values in mean, median, mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6229b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1da2a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: int, experience: int, salary: int]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv('age_1.csv', header = True, inferSchema = True) # if inferSchema is false it will consider all the values as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93a96728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('age_1.csv', header = True, inferSchema = True)\n",
    "# if inferSchema = True it will consider the strings as strings and numbers as int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3289d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|srinath|  32|         4| 10000|\n",
      "|    kad|  31|         5| 62613|\n",
      "|    das|   3|         2| 51658|\n",
      "|    dad|  45|        23| 96512|\n",
      "|    mom|NULL|        22| 13585|\n",
      "| dravid|  88|        32|  NULL|\n",
      "|   NULL|  64|      NULL| 65465|\n",
      "| sachin|NULL|        39| 65489|\n",
      "|  dhoni|  22|      NULL| 33333|\n",
      "|  aabbc|NULL|      NULL|  NULL|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7266f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|experience|salary|\n",
      "+----+----------+------+\n",
      "|  32|         4| 10000|\n",
      "|  31|         5| 62613|\n",
      "|   3|         2| 51658|\n",
      "|  45|        23| 96512|\n",
      "|NULL|        22| 13585|\n",
      "|  88|        32|  NULL|\n",
      "|  64|      NULL| 65465|\n",
      "|NULL|        39| 65489|\n",
      "|  22|      NULL| 33333|\n",
      "|NULL|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## drop the columns\n",
    "df_pyspark.drop('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1c07e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|srinath|  32|         4| 10000|\n",
      "|    kad|  31|         5| 62613|\n",
      "|    das|   3|         2| 51658|\n",
      "|    dad|  45|        23| 96512|\n",
      "|    mom|NULL|        22| 13585|\n",
      "| dravid|  88|        32|  NULL|\n",
      "|   NULL|  64|      NULL| 65465|\n",
      "| sachin|NULL|        39| 65489|\n",
      "|  dhoni|  22|      NULL| 33333|\n",
      "|  aabbc|NULL|      NULL|  NULL|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de29eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|experience|salary|\n",
      "+-------+---+----------+------+\n",
      "|srinath| 32|         4| 10000|\n",
      "|    kad| 31|         5| 62613|\n",
      "|    das|  3|         2| 51658|\n",
      "|    dad| 45|        23| 96512|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# it will drop all the rows where null values are present\n",
    "\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f14b050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|srinath|  32|         4| 10000|\n",
      "|    kad|  31|         5| 62613|\n",
      "|    das|   3|         2| 51658|\n",
      "|    dad|  45|        23| 96512|\n",
      "|    mom|NULL|        22| 13585|\n",
      "| dravid|  88|        32|  NULL|\n",
      "|   NULL|  64|      NULL| 65465|\n",
      "| sachin|NULL|        39| 65489|\n",
      "|  dhoni|  22|      NULL| 33333|\n",
      "|  aabbc|NULL|      NULL|  NULL|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any = how\n",
    "df_pyspark.na.drop(how = 'all').show() # it will drop the rows only if all the columns are null in that particular row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c29fc035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|experience|salary|\n",
      "+-------+---+----------+------+\n",
      "|srinath| 32|         4| 10000|\n",
      "|    kad| 31|         5| 62613|\n",
      "|    das|  3|         2| 51658|\n",
      "|    dad| 45|        23| 96512|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any').show() # it will drop the rows if any one particular column in that row has a null value\n",
    "# by default how value should be any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20545e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|srinath|  32|         4| 10000|\n",
      "|    kad|  31|         5| 62613|\n",
      "|    das|   3|         2| 51658|\n",
      "|    dad|  45|        23| 96512|\n",
      "|    mom|NULL|        22| 13585|\n",
      "| dravid|  88|        32|  NULL|\n",
      "|   NULL|  64|      NULL| 65465|\n",
      "| sachin|NULL|        39| 65489|\n",
      "|  dhoni|  22|      NULL| 33333|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold\n",
    "df_pyspark.na.drop(how = 'any', thresh =2).show()  # it will check the threshold of not null values, \n",
    "# in the above the syntax means :incase if there are atlest 2 not null values, keep them in the rows else delete the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7945ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|srinath|  32|         4| 10000|\n",
      "|    kad|  31|         5| 62613|\n",
      "|    das|   3|         2| 51658|\n",
      "|    dad|  45|        23| 96512|\n",
      "|    mom|NULL|        22| 13585|\n",
      "| dravid|  88|        32|  NULL|\n",
      "| sachin|NULL|        39| 65489|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#subset -- means applying the drop command to any particular column\n",
    "df_pyspark.na.drop(how = 'any',subset = 'experience').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c493f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|experience|salary|\n",
      "+-------+---+----------+------+\n",
      "|srinath| 32|         4| 10000|\n",
      "|    kad| 31|         5| 62613|\n",
      "|    das|  3|         2| 51658|\n",
      "|    dad| 45|        23| 96512|\n",
      "| dravid| 88|        32|  NULL|\n",
      "|   NULL| 64|      NULL| 65465|\n",
      "|  dhoni| 22|      NULL| 33333|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how = 'any',subset = 'age').show() # in the age column where ever there are null values that rows are deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a7cf207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+\n",
      "|        name|         age|  experience|      salary|\n",
      "+------------+------------+------------+------------+\n",
      "|     srinath|          32|           4|       10000|\n",
      "|         kad|          31|           5|       62613|\n",
      "|         das|           3|           2|       51658|\n",
      "|         dad|          45|          23|       96512|\n",
      "|         mom|hare Krishna|          22|       13585|\n",
      "|      dravid|          88|          32|hare Krishna|\n",
      "|hare Krishna|          64|hare Krishna|       65465|\n",
      "|      sachin|hare Krishna|          39|       65489|\n",
      "|       dhoni|          22|hare Krishna|       33333|\n",
      "|       aabbc|hare Krishna|hare Krishna|hare Krishna|\n",
      "+------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## fill the missing values\n",
    "df_pyspark.na.fill('hare Krishna').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "117c6549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------+------+\n",
      "|   name| age|   experience|salary|\n",
      "+-------+----+-------------+------+\n",
      "|srinath|  32|            4| 10000|\n",
      "|    kad|  31|            5| 62613|\n",
      "|    das|   3|            2| 51658|\n",
      "|    dad|  45|           23| 96512|\n",
      "|    mom|NULL|           22| 13585|\n",
      "| dravid|  88|           32|  NULL|\n",
      "|   NULL|  64|missing value| 65465|\n",
      "| sachin|NULL|           39| 65489|\n",
      "|  dhoni|  22|missing value| 33333|\n",
      "|  aabbc|NULL|missing value|  NULL|\n",
      "+-------+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('missing value','experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b82f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+\n",
      "|   name|    age|experience|salary|\n",
      "+-------+-------+----------+------+\n",
      "|srinath|     32|         4| 10000|\n",
      "|    kad|     31|         5| 62613|\n",
      "|    das|      3|         2| 51658|\n",
      "|    dad|     45|        23| 96512|\n",
      "|    mom|missing|        22| 13585|\n",
      "| dravid|     88|        32|  NULL|\n",
      "|   NULL|     64|   missing| 65465|\n",
      "| sachin|missing|        39| 65489|\n",
      "|  dhoni|     22|   missing| 33333|\n",
      "|  aabbc|missing|   missing|  NULL|\n",
      "+-------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('missing',['experience','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8daa2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing values with their mean, median or mode\n",
    "#we use imputer function\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "inputCols = ['age','experience','salary'],\n",
    "outputCols = [\"{}_imputed\".format(c) for c in ['age','experience','salary']]).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d69b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   name| age|experience|salary|age_imputed|experience_imputed|salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|srinath|  32|         4| 10000|         32|                 4|         10000|\n",
      "|    kad|  31|         5| 62613|         31|                 5|         62613|\n",
      "|    das|   3|         2| 51658|          3|                 2|         51658|\n",
      "|    dad|  45|        23| 96512|         45|                23|         96512|\n",
      "|    mom|NULL|        22| 13585|         40|                22|         13585|\n",
      "| dravid|  88|        32|  NULL|         88|                32|         49831|\n",
      "|   NULL|  64|      NULL| 65465|         64|                18|         65465|\n",
      "| sachin|NULL|        39| 65489|         40|                39|         65489|\n",
      "|  dhoni|  22|      NULL| 33333|         22|                18|         33333|\n",
      "|  aabbc|NULL|      NULL|  NULL|         40|                18|         49831|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imputation columns to dataframe\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8118c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "inputCols = ['age','experience','salary'],\n",
    "outputCols = [\"{}_imputed\".format(c) for c in ['age','experience','salary']]).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "245a2f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   name| age|experience|salary|age_imputed|experience_imputed|salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|srinath|  32|         4| 10000|         32|                 4|         10000|\n",
      "|    kad|  31|         5| 62613|         31|                 5|         62613|\n",
      "|    das|   3|         2| 51658|          3|                 2|         51658|\n",
      "|    dad|  45|        23| 96512|         45|                23|         96512|\n",
      "|    mom|NULL|        22| 13585|         32|                22|         13585|\n",
      "| dravid|  88|        32|  NULL|         88|                32|         51658|\n",
      "|   NULL|  64|      NULL| 65465|         64|                22|         65465|\n",
      "| sachin|NULL|        39| 65489|         32|                39|         65489|\n",
      "|  dhoni|  22|      NULL| 33333|         22|                22|         33333|\n",
      "|  aabbc|NULL|      NULL|  NULL|         32|                22|         51658|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
